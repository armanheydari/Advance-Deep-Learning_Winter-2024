{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/armanheydari/Advance-Deep-Learning_Winter-2024/blob/main/Assignment2/cmpt489_828_a2_q2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CMPT 489/828 Assignment 2**\n",
        "\n",
        "Follow the instructions in this notebook and complete the missing code.\n",
        "\n",
        "**NOTE: Do Not Change Any Provided Code or Given Variable Names! Except changing gpu.**"
      ],
      "metadata": {
        "id": "HGh9xVJYL_e9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2**. Create a simple convolutional neural network using **torch.nn** module (**20 points**)\n"
      ],
      "metadata": {
        "id": "iue8Vhhv9zny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "from torch.nn import functional as F\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "# select gpu if possible\n",
        "# you can change \"cuda:0\" to select other gpus\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "id": "nRihqwkFZmzR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load CIFAR-10 dataset with pytorch\n",
        "# set batch_size\n",
        "batch_size = 100\n",
        "# convert to tensor, normalize\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616)),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_id = list(range(4000))\n",
        "val_id = list(range(4000, 5000))\n",
        "test_id = list(range(500))\n",
        "\n",
        "# subset dataset and create dataloader with batch_size\n",
        "train_sub_set = torch.utils.data.Subset(trainset, train_id)\n",
        "val_sub_set = torch.utils.data.Subset(trainset, val_id)\n",
        "test_sub_set = torch.utils.data.Subset(testset, test_id)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_sub_set, batch_size=batch_size, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_sub_set, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_sub_set, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# check data size, should be (C,H,W), class map only useful for visualization and sanity checks\n",
        "image_size = trainset[0][0].size()\n",
        "class_map = {0: 'plane', 1: 'car', 2: 'bird', 3: 'cat', 4: 'deer', 5: 'dog', 6: 'frog', 7: 'horse', 8: 'ship',\n",
        "             9: 'truck'}"
      ],
      "metadata": {
        "id": "FzV2t1meZ3Nb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "a. Implement a CNN model (**4 points**)"
      ],
      "metadata": {
        "id": "_c4d51xzk8vf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleCnn(nn.Module):\n",
        "    def __init__(self, nb_hidden):\n",
        "        super().__init__()\n",
        "        ###############################################################################\n",
        "        # TODO:                                                                       #\n",
        "        # 1. create conv1 layer:                                                      #\n",
        "        #   with 32 output channels, 5x5 kernels, use default for others              #\n",
        "        # 2. create conv2 layer:                                                      #\n",
        "        #   with 64 output channels, 5x5 kernels, use default for others              #\n",
        "        # 3. create linear layer fc1: with nb_hidden output channels                  #\n",
        "        # 4. create linear layer fc2: with 10 output channels                         #\n",
        "        ###############################################################################\n",
        "        # *****BEGIN YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "        self.conv_layer1 =\n",
        "        self.conv_layer2 =\n",
        "        self.fully_connected1 =\n",
        "        self.fully_connected2 =\n",
        "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        forward step\n",
        "        :param x: input tensor\n",
        "        :return: output tensor\n",
        "        \"\"\"\n",
        "        ###############################################################################\n",
        "        # TODO:                                                                       #\n",
        "        # 1. create first convolution block c1_out:                                   #\n",
        "        #   relu(max_pool(conv1(), kernel_size=3, stride=3)                           #\n",
        "        # 2. create second convolution block c2_out:                                  #\n",
        "        #   relu(max_pool(conv2(), kernel_size=2, stride=2)                           #\n",
        "        # 3. create fully connected block fc1_out: relu(fc1())                        #\n",
        "        # 4. connect last fully connected layer fc2_out: fc2()                        #\n",
        "        # 5. return fc2_out                                                           #\n",
        "        ###############################################################################\n",
        "        # *****BEGIN YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "        c1_out =\n",
        "        c2_out =\n",
        "        fc1_out =\n",
        "        fc2_out =\n",
        "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****"
      ],
      "metadata": {
        "id": "7mow_daeaJpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "b. Train function (**8 points**)"
      ],
      "metadata": {
        "id": "ogiDUq5Kl4De"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train function\n",
        "def train_model(model, train_loader, val_loader, nb_epochs=100):\n",
        "    ###############################################################################\n",
        "    # TODO:                                                                       #\n",
        "    # 1. create loss: criterion use CrossEntropyLoss()                            #\n",
        "    # 2. create optimizer: optimizer use optim.Adam()                             #\n",
        "    ###############################################################################\n",
        "    # *****BEGIN YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "    criterion =\n",
        "    optimizer =\n",
        "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "    # initialize loss/acc dict storage\n",
        "    history = {\n",
        "        \"train_loss\": [],\n",
        "        \"train_acc\": [],\n",
        "        \"val_loss\": [],\n",
        "        \"val_acc\": []\n",
        "    }\n",
        "    train_steps = len(train_loader.dataset) // batch_size\n",
        "    val_steps = len(val_loader.dataset) // batch_size\n",
        "\n",
        "    # run for nb_epochs\n",
        "    for e in range(nb_epochs):\n",
        "        # set the model in training mode\n",
        "        model.train()\n",
        "        # initialize the total training and validation loss\n",
        "        epoch_train_loss = 0\n",
        "        epoch_val_loss = 0\n",
        "        # initialize the number of correct predictions in the training\n",
        "        # and validation step\n",
        "        train_correct = 0\n",
        "        val_correct = 0\n",
        "\n",
        "        for x, y in train_loader:\n",
        "            ###############################################################################\n",
        "            # TODO:                                                                       #\n",
        "            # 1. move x, y to device                                                      #\n",
        "            # 2. clear optimizer gradients                                                #\n",
        "            # 3. predict batch x, save in pred                                            #\n",
        "            # 4. calculate batch loss, save in loss                                       #\n",
        "            # 5. step optimizer                                                           #\n",
        "            ###############################################################################\n",
        "            # *****BEGIN YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "            # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "            # add the loss to the total training loss so far and\n",
        "            # calculate the number of correct predictions\n",
        "            epoch_train_loss += loss\n",
        "            train_correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "        # switch off autograd for validation\n",
        "        with torch.no_grad():\n",
        "            # set the model in evaluation mode\n",
        "            model.eval()\n",
        "            # loop over the validation set\n",
        "            for (x, y) in val_loader:\n",
        "                ###############################################################################\n",
        "                # TODO:                                                                       #\n",
        "                # 1. move x, y to device                                                      #\n",
        "                # 2. predict batch x, save in pred                                            #\n",
        "                # 3. update epoch_val_loss                                                    #\n",
        "                # 5. update val_correct                                                       #\n",
        "                ###############################################################################\n",
        "                # *****BEGIN YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "                # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "\n",
        "        # calculate the average epoch training and validation loss\n",
        "        mean_train_loss = epoch_train_loss / train_steps\n",
        "        mean_val_loss = epoch_val_loss / val_steps\n",
        "        # calculate the training and validation accuracy\n",
        "        train_correct = train_correct / len(train_loader.dataset)\n",
        "        val_correct = val_correct / len(val_loader.dataset)\n",
        "        # update our training history\n",
        "        history[\"train_loss\"].append(mean_train_loss.cpu().detach().numpy())\n",
        "        history[\"train_acc\"].append(train_correct)\n",
        "        history[\"val_loss\"].append(mean_val_loss.cpu().detach().numpy())\n",
        "        history[\"val_acc\"].append(val_correct)\n",
        "        # print the model training and validation information\n",
        "        print(\"[INFO] EPOCH: {}/{}\".format(e + 1, nb_epochs))\n",
        "        print(\"Train loss: {:.6f}, Train accuracy: {:.4f}\".format(\n",
        "            mean_train_loss, train_correct))\n",
        "        print(\"Val loss: {:.6f}, Val accuracy: {:.4f}\\n\".format(\n",
        "            mean_val_loss, val_correct))"
      ],
      "metadata": {
        "id": "5knm0wl63s0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "c. Test function (**3 points**)"
      ],
      "metadata": {
        "id": "ptMUvPj7mWJv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, test_loader):\n",
        "    # we can now evaluate the network on the test set\n",
        "    print(\"[INFO] testing SimpleCnn...\")\n",
        "    # turn off autograd for testing evaluation\n",
        "    ###############################################################################\n",
        "    # TODO:                                                                       #\n",
        "    # 1. initialize test correct counter: test_correct                            #\n",
        "    # 2. switch off autograd                                                      #\n",
        "    # 3. put model in evaluation mode                                             #\n",
        "    # 4. loop over test_loader                                                    #\n",
        "    # 5. move data to device                                                      #\n",
        "    # 6. predict batch x, save in pred                                            #\n",
        "    # 7. update test_correct                                                      #\n",
        "    # 8. calculate average test accuracy                                          #\n",
        "    # 9. print average test accuracy                                              #\n",
        "    ###############################################################################\n",
        "    # *****BEGIN YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****"
      ],
      "metadata": {
        "id": "-vTW3OEkjVn8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "d. Train and test your model (**3 points**)"
      ],
      "metadata": {
        "id": "eSUokLNsoNiV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###############################################################################\n",
        "# TODO:                                                                       #\n",
        "# 1. create model instance with 500 neurons for first linear layer            #\n",
        "# 2. call training loop, train for 300 epochs                                 #\n",
        "# 3. call test function                                                       #\n",
        "###############################################################################\n",
        "# *****BEGIN YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "model =\n",
        "# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****"
      ],
      "metadata": {
        "id": "nNanro4JoVgz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "d. Experiment with model architecture (**2 points**)\n",
        "\n",
        "Try different number of neurons for the first linear layer. Do you notice any performance difference?\n",
        "\n",
        "Also try a CNN with an additional conv block (conv+pool+relu).\n",
        "\n",
        "You can use different kernerl sizes for you conv/pool layer.\n",
        "\n",
        "\n",
        "Do you notice any performance difference?"
      ],
      "metadata": {
        "id": "mK6GVJbLojK0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###############################################################################\n",
        "# TODO:                                                                       #\n",
        "# 1. Experiment with different nb_hidden values for your CNN                  #\n",
        "# Take note of the performance changes                                        #\n",
        "# 2. Create another CNN with one more conv block                              #\n",
        "# Take note of the performance changes                                        #\n",
        "###############################################################################\n",
        "# *****BEGIN YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****"
      ],
      "metadata": {
        "id": "sXTOYAsnpLdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "# clean up, release memory\n",
        "model.cpu()\n",
        "del model\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "xs4vs5z5oY-l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}